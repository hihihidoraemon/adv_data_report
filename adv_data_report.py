import streamlit as st
import pandas as pd
import numpy as np
import re
import os
from datetime import datetime, date, timedelta
import base64
from io import BytesIO
import tempfile

# ==================== Streamlité¡µé¢é…ç½®ï¼ˆå¿…é¡»æ”¾åœ¨æœ€å‰é¢ï¼‰ ====================
st.set_page_config(
    page_title="ç½‘ç›Ÿæ—¥æŠ¥è¾“å‡º",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== æ ·å¼é…ç½® ====================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 15px;
        margin: 10px 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 15px;
        margin: 10px 0;
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    .upload-area {
        border: 2px dashed #ccc;
        border-radius: 10px;
        padding: 30px;
        text-align: center;
        margin: 20px 0;
        background-color: #f9f9f9;
    }
</style>
""", unsafe_allow_html=True)

# ==================== æ ¸å¿ƒå¤„ç†å‡½æ•° ====================
def process_daily_report_web(uploaded_file, progress_bar=None, status_text=None):
    """
    ç½‘é¡µç‰ˆå¤„ç†æ—¥æŠ¥Excelæ•°æ®çš„ä¸»å‡½æ•°
    """
    
    # æ›´æ–°è¿›åº¦
    if progress_bar and status_text:
        progress_bar.progress(5)
        status_text.text("ğŸ“ æ­£åœ¨è¯»å–Excelæ–‡ä»¶...")
    
    # ====================== 1ã€å¯¼å…¥Excelæ•°æ® ======================
    try:
        sheet1_all_data = pd.read_excel(uploaded_file, sheet_name='1--all data')
        sheet3_advertiser = pd.read_excel(uploaded_file, sheet_name='3--åŒ¹é…å¹¿å‘Šä¸»')
        sheet4_reject = pd.read_excel(uploaded_file, sheet_name='4--rejectäº‹ä»¶')
        sheet2_reject_rule = pd.read_excel(uploaded_file, sheet_name='2-rejectè§„åˆ™')
        
        if progress_bar and status_text:
            progress_bar.progress(15)
            status_text.text("âœ… æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼Œå¼€å§‹æ•°æ®å¤„ç†...")
            
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
    
    # ====================== å…³é”®ä¼˜åŒ–ï¼šè‡ªåŠ¨è¯†åˆ«æœ€æ–°ä¸¤å¤©æ—¥æœŸ ======================
    if progress_bar and status_text:
        progress_bar.progress(20)
        status_text.text("ğŸ“… è‡ªåŠ¨è¯†åˆ«æœ€æ–°ä¸¤å¤©æ—¥æœŸ...")
    
    sheet1_all_data['Date'] = sheet1_all_data['Time'].dt.date
    sheet4_reject['Date'] = sheet4_reject['Time'].dt.date
    
    # è·å–æ‰€æœ‰å”¯ä¸€æ—¥æœŸå¹¶æ’åº
    all_dates = sorted(sheet1_all_data['Date'].unique(), reverse=True)
    
    if len(all_dates) < 2:
        raise Exception(f"é”™è¯¯ï¼šæ•°æ®ä¸­ä»…åŒ…å« {len(all_dates)} å¤©æ•°æ®ï¼Œè‡³å°‘éœ€è¦2å¤©ï¼")
    
    # å®šä¹‰æœ€æ–°ä¸¤å¤©ï¼ˆæ ¸å¿ƒæ—¥æœŸå˜é‡ï¼‰
    newest_date = all_dates[0]       # æœ€æ–°ä¸€å¤©
    second_newest_date = all_dates[1] # æ¬¡æ–°ä¸€å¤©
    
    # ç”Ÿæˆæ—¥æœŸæ˜¾ç¤ºåç§°
    newest_date_str = f"{newest_date.year}/{newest_date.month}/{newest_date.day}"
    second_newest_date_str = f"{second_newest_date.year}/{second_newest_date.month}/{second_newest_date.day}"
    newest_date_file_str = f"{newest_date.year}{newest_date.month:02d}{newest_date.day:02d}"
    
    date_mapping = {
        'newest': {
            'date': newest_date,
            'str': newest_date_str,
            'file_str': newest_date_file_str,
            'col_name': f"{newest_date_str} Total Revenue",
            'reject_rate_col': f"{newest_date_str} rejectç‡(%)"
        },
        'second': {
            'date': second_newest_date,
            'str': second_newest_date_str,
            'col_name': f"{second_newest_date_str} Total Revenue",
            'reject_rate_col': f"{second_newest_date_str} rejectç‡(%)"
        }
    }
    
    # ====================== 2ã€åŸºç¡€æ•°æ®é¢„å¤„ç† ======================
    if progress_bar and status_text:
        progress_bar.progress(30)
        status_text.text("ğŸ”§ åŸºç¡€æ•°æ®é¢„å¤„ç†...")
    
    # æå–æ¯ä¸ªOffer IDçš„æœ€æ–°Status
    offer_status_mapping = sheet1_all_data[sheet1_all_data['Date'] == newest_date][
        ['Offer ID', 'Status']
    ].drop_duplicates(subset=['Offer ID']).fillna('Unknown')
    
    # ç²¾å‡†åˆ¤æ–­æ–°æ—§é¢„ç®—
    non_newest_data = sheet1_all_data[sheet1_all_data['Date'] != newest_date].copy()
    six_days_ago = newest_date - timedelta(days=6)
    past_6_days_data = non_newest_data[non_newest_data['Date'] >= six_days_ago].copy()
    old_budget_offers = set(
        past_6_days_data[past_6_days_data['Total Revenue'] > 0]['Offer ID'].unique()
    )
    all_offers = set(sheet1_all_data['Offer ID'].unique())
    
    def judge_budget_type(offer_id):
        return 'æ—§é¢„ç®—' if offer_id in old_budget_offers else 'æ–°é¢„ç®—'
    
    # ====================== 3ã€åŒ¹é…å¹¿å‘Šä¸»ä¿¡æ¯ ======================
    if progress_bar and status_text:
        progress_bar.progress(40)
        status_text.text("ğŸ”— åŒ¹é…å¹¿å‘Šä¸»ä¿¡æ¯...")
    
    sheet1_all_data = pd.merge(
        sheet1_all_data, 
        sheet3_advertiser[['Advertiser', 'äºŒçº§å¹¿å‘Šä¸»', 'ä¸‰çº§å¹¿å‘Šä¸»']], 
        on='Advertiser', 
        how='left'
    )
    
    # ====================== 4ã€æ ¸å¿ƒè®¡ç®—ï¼šOfferçº§åˆ«çš„åŸºç¡€æ•°æ® ======================
    if progress_bar and status_text:
        progress_bar.progress(50)
        status_text.text("ğŸ“Š è®¡ç®—Offerçº§åˆ«æ•°æ®...")
    
    # æå–App IDæ˜ å°„
    offer_app_mapping = sheet1_all_data[['Offer ID', 'App ID']].drop_duplicates(subset=['Offer ID']).fillna('')
    
    # è®¡ç®—æ¯ä¸ªOffer IDåœ¨æœ€æ–°/æ¬¡æ–°ä¸€å¤©çš„æ€»æ”¶å…¥
    offer_newest_revenue = sheet1_all_data[sheet1_all_data['Date'] == newest_date].groupby('Offer ID').agg({
        'Total Revenue': 'sum'
    }).reset_index()
    offer_newest_revenue.columns = ['Offer ID', date_mapping['newest']['col_name']]
    
    offer_second_revenue = sheet1_all_data[sheet1_all_data['Date'] == second_newest_date].groupby('Offer ID').agg({
        'Total Revenue': 'sum'
    }).reset_index()
    offer_second_revenue.columns = ['Offer ID', date_mapping['second']['col_name']]
    
    # åˆå¹¶OfferåŸºç¡€æ•°æ®
    offer_base_data = offer_app_mapping.copy()
    offer_base_data = pd.merge(offer_base_data, offer_status_mapping, on='Offer ID', how='left')
    offer_base_data = pd.merge(offer_base_data, offer_newest_revenue, on='Offer ID', how='left').fillna(0)
    offer_base_data = pd.merge(offer_base_data, offer_second_revenue, on='Offer ID', how='left').fillna(0)
    
    # è®¡ç®—Offerçº§æµæ°´å·®
    offer_base_data['æµæ°´å·®ï¼ˆæœ€æ–°-æ¬¡æ–°ï¼‰'] = (
        offer_base_data[date_mapping['newest']['col_name']] - 
        offer_base_data[date_mapping['second']['col_name']]
    )
    
    def calculate_offer_change_pct(row):
        prev_revenue = row[date_mapping['second']['col_name']]
        curr_revenue = row[date_mapping['newest']['col_name']]
        if prev_revenue == 0:
            return 1000.0 if curr_revenue > 0 else 0.0
        return ((curr_revenue - prev_revenue) / abs(prev_revenue)) * 100
    
    offer_base_data['å˜åŒ–å¹…åº¦(%)'] = offer_base_data.apply(calculate_offer_change_pct, axis=1)
    offer_base_data['é¢„ç®—ç±»å‹'] = offer_base_data['Offer ID'].apply(judge_budget_type)
    
    # é«˜å·®å¼‚Offerç­›é€‰
    high_diff_mask = (offer_base_data['æµæ°´å·®ï¼ˆæœ€æ–°-æ¬¡æ–°ï¼‰'].abs() >= 10)
    high_diff_offers = offer_base_data[high_diff_mask]['Offer ID'].tolist()
    
    # ====================== 5ã€Affiliateç»´åº¦ç²¾å‡†åˆ†æ ======================
    if progress_bar and status_text:
        progress_bar.progress(60)
        status_text.text("ğŸ‘¥ Affiliateç»´åº¦åˆ†æ...")
    
    offer_influence = pd.DataFrame(columns=['Offer ID', 'influence affiliate'])
    
    if high_diff_offers:
        # æŒ‰Offer ID + Affiliate + Dateåˆ†ç»„è®¡ç®—
        affiliate_daily_metrics = sheet1_all_data[sheet1_all_data['Offer ID'].isin(high_diff_offers)].groupby(
            ['Offer ID', 'Affiliate', 'Date']
        ).agg({
            'Total Revenue': 'sum',
            'Total Clicks': 'sum',
            'Total Conversions': 'sum'
        }).reset_index()
        
        # åˆ†åˆ«æå–æœ€æ–°/æ¬¡æ–°ä¸€å¤©æ•°æ®
        aff_newest = affiliate_daily_metrics[affiliate_daily_metrics['Date'] == newest_date].copy()
        aff_newest.columns = ['Offer ID', 'Affiliate', 'Date', 'Revenue_newest', 'Clicks_newest', 'Conversions_newest']
        
        aff_second = affiliate_daily_metrics[affiliate_daily_metrics['Date'] == second_newest_date].copy()
        aff_second.columns = ['Offer ID', 'Affiliate', 'Date', 'Revenue_second', 'Clicks_second', 'Conversions_second']
        
        # åˆå¹¶ä¸¤å¤©æ•°æ®
        aff_merged = pd.merge(
            aff_newest, aff_second, 
            on=['Offer ID', 'Affiliate'], 
            how='outer'
        ).fillna(0)
        
        # è®¡ç®—å·®å¼‚æŒ‡æ ‡
        aff_merged['Revenue_Diff'] = aff_merged['Revenue_newest'] - aff_merged['Revenue_second']
        aff_merged['Clicks_Diff'] = aff_merged['Clicks_newest'] - aff_merged['Clicks_second']
        aff_merged['Clicks_Change_Pct'] = np.where(
            aff_merged['Clicks_second'] > 0,
            (aff_merged['Clicks_Diff'] / aff_merged['Clicks_second']) * 100,
            np.where(aff_merged['Clicks_newest'] > 0, 1000.0, 0.0)
        )
        
        # CRè®¡ç®—
        aff_merged['CR_newest'] = np.where(
            aff_merged['Clicks_newest'] > 0,
            (aff_merged['Conversions_newest'] / aff_merged['Clicks_newest']) * 100,
            0.0
        )
        aff_merged['CR_second'] = np.where(
            aff_merged['Clicks_second'] > 0,
            (aff_merged['Conversions_second'] / aff_merged['Clicks_second']) * 100,
            0.0
        )
        aff_merged['CR_Change_Abs'] = aff_merged['CR_newest'] - aff_merged['CR_second']
        
        # ç­›é€‰æœ‰æ˜¾è‘—æ”¶å…¥å˜åŒ–çš„Affiliate
        significant_aff = aff_merged[aff_merged['Revenue_Diff'].abs() >= 5].copy()
        significant_aff = significant_aff.sort_values(by='Revenue_Diff', ascending=False)
        
        def generate_influence_text(row):
            affiliate = row['Affiliate']
            revenue_newest = row['Revenue_newest']
            revenue_second = row['Revenue_second']
            revenue_diff = row['Revenue_Diff']
            clicks_change = row['Clicks_Change_Pct']
            cr_change = row['CR_Change_Abs']
            
            if revenue_newest > 0 and revenue_second == 0:
                return f"{affiliate} æ–°å¢äº§ç”Ÿæµæ°´ {revenue_newest:.2f} ç¾é‡‘"
            elif revenue_newest == 0 and revenue_second > 0:
                return f"{affiliate} åœæ­¢äº§ç”Ÿæµæ°´ï¼Œå‡å°‘ {revenue_second:.2f} ç¾é‡‘"
            else:
                if revenue_second != 0:
                    revenue_change_pct = (revenue_diff / abs(revenue_second)) * 100
                else:
                    revenue_change_pct = 1000.0 if revenue_diff > 0 else -1000.0
                
                if revenue_diff > 0:
                    base_text = f"{affiliate} å¢åŠ  {revenue_diff:.2f} ç¾é‡‘/{abs(revenue_change_pct):.1f}%"
                else:
                    base_text = f"{affiliate} å‡å°‘ {abs(revenue_diff):.2f} ç¾é‡‘/{abs(revenue_change_pct):.1f}%"
                
                reasons = []
                direction = "å¢åŠ " if clicks_change > 0 else "å‡å°‘"
                reasons.append(f"Total Clicks{direction}{abs(clicks_change):.1f}%")
                direction = "å¢åŠ " if cr_change > 0 else "å‡å°‘"
                reasons.append(f"CR{direction}{abs(cr_change):.1f}%")
                
                return f"{base_text}ï¼Œå¯¹åº”{', '.join(reasons)}"
        
        significant_aff['influence_text'] = significant_aff.apply(generate_influence_text, axis=1)
        offer_influence = significant_aff.groupby('Offer ID')['influence_text'].apply(
            lambda x: '\n'.join(x)
        ).reset_index()
        offer_influence.columns = ['Offer ID', 'influence affiliate']
    
    # ====================== 6ã€ç”Ÿæˆå››ä¸ªæ ¸å¿ƒè¡¨æ ¼ ======================
    if progress_bar and status_text:
        progress_bar.progress(70)
        status_text.text("ğŸ“ˆ ç”Ÿæˆæ ¸å¿ƒåˆ†æè¡¨æ ¼...")
    
    # è¡¨æ ¼ä¸€ï¼šä¸‰çº§å¹¿å‘Šä¸»æ—¥æŠ¥è¡¨
    table1_data = sheet1_all_data[sheet1_all_data['Date'].isin([newest_date, second_newest_date])].groupby(
        ['ä¸‰çº§å¹¿å‘Šä¸»', 'Date']
    ).agg({
        'Total Revenue': 'sum',
        'Total Profit': 'sum'
    }).reset_index()
    
    table1 = pd.DataFrame()
    table1['ä¸‰çº§å¹¿å‘Šä¸»'] = table1_data['ä¸‰çº§å¹¿å‘Šä¸»'].unique()
    
    for date_type in ['newest', 'second']:
        current_date = date_mapping[date_type]['date']
        current_date_str = date_mapping[date_type]['str']
        temp = table1_data[table1_data['Date'] == current_date].set_index('ä¸‰çº§å¹¿å‘Šä¸»')
        table1[f"{current_date_str} Total Revenue"] = table1['ä¸‰çº§å¹¿å‘Šä¸»'].map(temp['Total Revenue']).fillna(0)
        table1[f"{current_date_str} Total Profit"] = table1['ä¸‰çº§å¹¿å‘Šä¸»'].map(temp['Total Profit']).fillna(0)
    
    table1 = table1[
        ['ä¸‰çº§å¹¿å‘Šä¸»', 
         f"{newest_date_str} Total Revenue", f"{newest_date_str} Total Profit",
         f"{second_newest_date_str} Total Revenue", f"{second_newest_date_str} Total Profit"]
    ].copy().round(2)
    
    # è¡¨æ ¼äºŒï¼šé«˜å·®å¼‚Offer IDè¯¦æƒ…
    if high_diff_offers:
        offer_details = sheet1_all_data[sheet1_all_data['Offer ID'].isin(high_diff_offers)][
            ['Offer ID', 'GEO', 'Advertiser']
        ].drop_duplicates(subset=['Offer ID']).reset_index(drop=True)
        
        table2 = pd.merge(offer_details, offer_base_data[
            ['Offer ID', 'App ID', 'Status', date_mapping['newest']['col_name'], 
             date_mapping['second']['col_name'], 'æµæ°´å·®ï¼ˆæœ€æ–°-æ¬¡æ–°ï¼‰', 'å˜åŒ–å¹…åº¦(%)', 'é¢„ç®—ç±»å‹']
        ], on='Offer ID', how='left')
        
        table2 = pd.merge(table2, offer_influence, on='Offer ID', how='left')
        table2['influence affiliate'] = table2['influence affiliate'].fillna('æ— æ˜¾è‘—å˜åŒ–')
        
        table2 = table2[
            ['Offer ID', 'App ID', 'Status', 'GEO', 'Advertiser',
             date_mapping['newest']['col_name'], date_mapping['second']['col_name'],
             'æµæ°´å·®ï¼ˆæœ€æ–°-æ¬¡æ–°ï¼‰', 'å˜åŒ–å¹…åº¦(%)', 'é¢„ç®—ç±»å‹', 'influence affiliate']
        ].copy()
        
        numeric_cols_table2 = [
            date_mapping['newest']['col_name'], date_mapping['second']['col_name'],
            'æµæ°´å·®ï¼ˆæœ€æ–°-æ¬¡æ–°ï¼‰', 'å˜åŒ–å¹…åº¦(%)'
        ]
        table2[numeric_cols_table2] = table2[numeric_cols_table2].round(2)
    else:
        table2 = pd.DataFrame(columns=[
            'Offer ID', 'App ID', 'Status', 'GEO', 'Advertiser',
            date_mapping['newest']['col_name'], date_mapping['second']['col_name'],
            'æµæ°´å·®ï¼ˆæœ€æ–°-æ¬¡æ–°ï¼‰', 'å˜åŒ–å¹…åº¦(%)', 'é¢„ç®—ç±»å‹', 'influence affiliate'
        ])
    
     # ---------------------- è¡¨æ ¼ä¸‰ï¼šäºŒçº§å¹¿å‘Šä¸»ç»¼åˆæŠ¥è¡¨ï¼ˆæ–°å¢rejectç‡ï¼‰ ----------------------
    print("æ ¸å¿ƒæ–°å¢ï¼šè¡¨æ ¼ä¸‰è®¡ç®—äºŒçº§å¹¿å‘Šä¸»rejectç‡...")
    table3 = pd.DataFrame()
    table3['äºŒçº§å¹¿å‘Šä¸»'] = sheet1_all_data['äºŒçº§å¹¿å‘Šä¸»'].unique()
    
    # å¡«å……æ”¶å…¥/åˆ©æ¶¦/è½¬åŒ–æ•°æ®
    for date_type in ['newest', 'second']:
        current_date = date_mapping[date_type]['date']
        current_date_str = date_mapping[date_type]['str']
        
        temp = sheet1_all_data[sheet1_all_data['Date'] == current_date].groupby('äºŒçº§å¹¿å‘Šä¸»').agg({
            'Total Revenue': 'sum',
            'Total Profit': 'sum',
            'Total Conversions': 'sum'
        }).reset_index()
        
        table3[f"{current_date_str} Total Revenue"] = table3['äºŒçº§å¹¿å‘Šä¸»'].map(temp.set_index('äºŒçº§å¹¿å‘Šä¸»')['Total Revenue']).fillna(0)
        table3[f"{current_date_str} Total Profit"] = table3['äºŒçº§å¹¿å‘Šä¸»'].map(temp.set_index('äºŒçº§å¹¿å‘Šä¸»')['Total Profit']).fillna(0)
        table3[f"{current_date_str} Total Conversions"] = table3['äºŒçº§å¹¿å‘Šä¸»'].map(temp.set_index('äºŒçº§å¹¿å‘Šä¸»')['Total Conversions']).fillna(0)
    
    # å¤„ç†4--rejectäº‹ä»¶æ•°æ®
    sheet4_reject = pd.merge(
        sheet4_reject, sheet3_advertiser[['Advertiser', 'äºŒçº§å¹¿å‘Šä¸»']], 
        on='Advertiser', how='left'
    )
    sheet4_reject['New Time'] = sheet4_reject['Time'].copy()
    appnext_mask = sheet4_reject['Advertiser'].str.contains('appnext', case=False, na=False)
    sheet4_reject.loc[appnext_mask, 'New Time'] = sheet4_reject.loc[appnext_mask, 'New Time'] - timedelta(days=1)
    sheet4_reject['New Date'] = sheet4_reject['New Time'].dt.date
    sheet4_reject = pd.merge(
        sheet4_reject, sheet2_reject_rule[['Event', 'æ˜¯å¦ä¸ºreject']], 
        on='Event', how='left'
    )
    
    # å¡«å……Rejectæ•°æ®
    reject_stats = sheet4_reject[sheet4_reject['New Date'].isin([newest_date, second_newest_date])].groupby(
        ['New Date', 'äºŒçº§å¹¿å‘Šä¸»']
    ).agg({
        'æ˜¯å¦ä¸ºreject': lambda x: (x == True).sum()
    }).reset_index()
    
    for date_type in ['newest', 'second']:
        current_date = date_mapping[date_type]['date']
        current_date_str = date_mapping[date_type]['str']
        
        temp = reject_stats[reject_stats['New Date'] == current_date].set_index('äºŒçº§å¹¿å‘Šä¸»')
        table3[f"{current_date_str} Total reject"] = table3['äºŒçº§å¹¿å‘Šä¸»'].map(temp['æ˜¯å¦ä¸ºreject']).fillna(0)
    
    # ========== æ ¸å¿ƒæ–°å¢ï¼šè®¡ç®—äºŒçº§å¹¿å‘Šä¸»rejectç‡ ==========
    def calculate_reject_rate(row, date_str):
        """
        è®¡ç®—rejectç‡ï¼šreject / (conversions + reject)
        åˆ†æ¯ä¸º0æ—¶è¿”å›0ï¼Œé¿å…é™¤ä»¥0é”™è¯¯
        """
        conversions = row[f"{date_str} Total Conversions"]
        reject = row[f"{date_str} Total reject"]
        total = conversions + reject
        if total == 0:
            return 0.0
        return (reject / total) * 100
    
    # è®¡ç®—æœ€æ–°/æ¬¡æ–°ä¸€å¤©çš„rejectç‡
    table3[date_mapping['newest']['reject_rate_col']] = table3.apply(
        lambda x: calculate_reject_rate(x, newest_date_str), axis=1
    ).round(2)
    
    table3[date_mapping['second']['reject_rate_col']] = table3.apply(
        lambda x: calculate_reject_rate(x, second_newest_date_str), axis=1
    ).round(2)
    
    # è°ƒæ•´åˆ—é¡ºåºå¹¶æ ¼å¼åŒ–
    table3 = table3[
        ['äºŒçº§å¹¿å‘Šä¸»', 
         f"{newest_date_str} Total Revenue", f"{newest_date_str} Total Profit",
         f"{second_newest_date_str} Total Revenue", f"{second_newest_date_str} Total Profit",
         f"{newest_date_str} Total Conversions", f"{newest_date_str} Total reject", date_mapping['newest']['reject_rate_col'],
         f"{second_newest_date_str} Total Conversions", f"{second_newest_date_str} Total reject", date_mapping['second']['reject_rate_col']]
    ].copy()
    
    numeric_cols_table3 = [f"{newest_date_str} Total Revenue", f"{newest_date_str} Total Profit",
                          f"{second_newest_date_str} Total Revenue", f"{second_newest_date_str} Total Profit",
                          date_mapping['newest']['reject_rate_col'], date_mapping['second']['reject_rate_col']]
    table3[numeric_cols_table3] = table3[numeric_cols_table3].round(2)
    
    int_cols_table3 = [f"{newest_date_str} Total Conversions", f"{newest_date_str} Total reject",
                      f"{second_newest_date_str} Total Conversions", f"{second_newest_date_str} Total reject"]
    table3[int_cols_table3] = table3[int_cols_table3].astype(int)
    
    # ---------------------- è¡¨æ ¼å››ï¼šAffiliateç»¼åˆæŠ¥è¡¨ï¼ˆæ–°å¢rejectç‡ï¼‰ ----------------------
    print("æ ¸å¿ƒæ–°å¢ï¼šè¡¨æ ¼å››è®¡ç®—Affiliate rejectç‡...")
    table4 = pd.DataFrame()
    table4['Affiliate'] = sheet1_all_data['Affiliate'].unique()
    
    # åŠ¨æ€å¡«å……ä¸¤å¤©çš„æ”¶å…¥/åˆ©æ¶¦/è½¬åŒ–æ•°æ®
    for date_type in ['newest', 'second']:
        current_date = date_mapping[date_type]['date']
        current_date_str = date_mapping[date_type]['str']
        
        daily_data = sheet1_all_data[sheet1_all_data['Date'] == current_date].groupby('Affiliate').agg({
            'Total Revenue': 'sum',
            'Total Profit': 'sum',
            'Total Conversions': 'sum',
            'äºŒçº§å¹¿å‘Šä¸»': lambda x: x.mode()[0] if not x.mode().empty else ''
        }).reset_index()
        
        table4[f"{current_date_str} Total Revenue"] = table4['Affiliate'].map(daily_data.set_index('Affiliate')['Total Revenue']).fillna(0)
        table4[f"{current_date_str} Total Profit"] = table4['Affiliate'].map(daily_data.set_index('Affiliate')['Total Profit']).fillna(0)
        table4[f"{current_date_str} Total Conversions"] = table4['Affiliate'].map(daily_data.set_index('Affiliate')['Total Conversions']).fillna(0)
        table4[f"{current_date_str} äºŒçº§å¹¿å‘Šä¸»"] = table4['Affiliate'].map(daily_data.set_index('Affiliate')['äºŒçº§å¹¿å‘Šä¸»']).fillna('')
    
    # åˆå¹¶äºŒçº§å¹¿å‘Šä¸»ä¿¡æ¯
    def merge_advertisers(row):
        adv1 = row[f"{second_newest_date_str} äºŒçº§å¹¿å‘Šä¸»"]
        adv2 = row[f"{newest_date_str} äºŒçº§å¹¿å‘Šä¸»"]
        advs = set()
        if adv1 and adv1 != '0':
            advs.add(str(adv1))
        if adv2 and adv2 != '0':
            advs.add(str(adv2))
        return '; '.join(advs)
    
    table4['äºŒçº§å¹¿å‘Šä¸»'] = table4.apply(merge_advertisers, axis=1)
    
    # å¡«å……Rejectæ•°æ®
    reject_long = pd.melt(
        table3[['äºŒçº§å¹¿å‘Šä¸»', f"{newest_date_str} Total reject", f"{second_newest_date_str} Total reject"]],
        id_vars=['äºŒçº§å¹¿å‘Šä¸»'],
        var_name='Date',
        value_name='Total reject'
    )
    reject_long['Date'] = reject_long['Date'].str.extract(r'(\d{4}/\d{1,2}/\d{1,2})')
    
    def get_affiliate_reject(row, target_date_str):
        if not row['äºŒçº§å¹¿å‘Šä¸»']:
            return 0
        total_reject = 0
        for adv in row['äºŒçº§å¹¿å‘Šä¸»'].split('; '):
            adv = adv.strip()
            reject_val = reject_long[
                (reject_long['äºŒçº§å¹¿å‘Šä¸»'] == adv) & 
                (reject_long['Date'] == target_date_str)
            ]['Total reject'].sum()
            total_reject += reject_val
        return total_reject
    
    # æ·»åŠ rejectåˆ—
    table4[f"{newest_date_str} Total reject"] = table4.apply(
        lambda x: get_affiliate_reject(x, newest_date_str), axis=1
    ).astype(int)
    
    table4[f"{second_newest_date_str} Total reject"] = table4.apply(
        lambda x: get_affiliate_reject(x, second_newest_date_str), axis=1
    ).astype(int)
    
    # ========== æ ¸å¿ƒæ–°å¢ï¼šè®¡ç®—Affiliate rejectç‡ ==========
    table4[date_mapping['newest']['reject_rate_col']] = table4.apply(
        lambda x: calculate_reject_rate(x, newest_date_str), axis=1
    ).round(2)
    
    table4[date_mapping['second']['reject_rate_col']] = table4.apply(
        lambda x: calculate_reject_rate(x, second_newest_date_str), axis=1
    ).round(2)
    
    # è°ƒæ•´åˆ—é¡ºåºå¹¶æ ¼å¼åŒ–
    table4 = table4[
        ['Affiliate', 
         f"{newest_date_str} Total Revenue", f"{newest_date_str} Total Profit",
         f"{second_newest_date_str} Total Revenue", f"{second_newest_date_str} Total Profit",
         f"{newest_date_str} Total Conversions", f"{newest_date_str} Total reject", date_mapping['newest']['reject_rate_col'],
         f"{second_newest_date_str} Total Conversions", f"{second_newest_date_str} Total reject", date_mapping['second']['reject_rate_col'],
         'äºŒçº§å¹¿å‘Šä¸»']
    ].copy()
    
    table4 = table4.fillna(0)
    numeric_cols_table4 = [f"{newest_date_str} Total Revenue", f"{newest_date_str} Total Profit",
                          f"{second_newest_date_str} Total Revenue", f"{second_newest_date_str} Total Profit",
                          date_mapping['newest']['reject_rate_col'], date_mapping['second']['reject_rate_col']]
    table4[numeric_cols_table4] = table4[numeric_cols_table4].round(2)
    
    int_cols_table4 = [f"{newest_date_str} Total Conversions", f"{newest_date_str} Total reject",
                      f"{second_newest_date_str} Total Conversions", f"{second_newest_date_str} Total reject"]
    table4[int_cols_table4] = table4[int_cols_table4].astype(int)
    table4 = table4.sort_values('Affiliate').reset_index(drop=True)


    
    if progress_bar and status_text:
        progress_bar.progress(90)
        status_text.text("ğŸ’¾ å‡†å¤‡ä¸‹è½½æ–‡ä»¶...")
    
    # è¿”å›æ‰€æœ‰ç»“æœ
    results = {
        'table1': table1,
        'table2': table2,
        'table3': table3,
        'table4': table4,
        'newest_date_str': newest_date_str,
        'newest_date_file_str': newest_date_file_str,
        'stats': {
            'é«˜å·®å¼‚Offeræ•°é‡': len(high_diff_offers),
            'æ—§é¢„ç®—Offeræ•°é‡': len(old_budget_offers),
            'æ–°é¢„ç®—Offeræ•°é‡': len(all_offers - old_budget_offers)
        }
    }
    
    if progress_bar and status_text:
        progress_bar.progress(100)
        status_text.text("ğŸ‰ åˆ†æå®Œæˆï¼")
    
    return results

# ==================== æ–‡ä»¶ä¸‹è½½åŠŸèƒ½ ====================
def get_excel_download_link(results):
    """ç”ŸæˆExcelæ–‡ä»¶ä¸‹è½½é“¾æ¥"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        results['table1'].to_excel(writer, sheet_name='è¡¨æ ¼ä¸€_ä¸‰çº§å¹¿å‘Šä¸»æ—¥æŠ¥è¡¨', index=False)
        results['table2'].to_excel(writer, sheet_name='è¡¨æ ¼äºŒ_é«˜å·®å¼‚Offer IDè¯¦æƒ…', index=False)
        results['table3'].to_excel(writer, sheet_name='è¡¨æ ¼ä¸‰_äºŒçº§å¹¿å‘Šä¸»ç»¼åˆæŠ¥è¡¨', index=False)
        results['table4'].to_excel(writer, sheet_name='è¡¨æ ¼å››_Affiliateç»¼åˆæŠ¥è¡¨', index=False)
    
    output.seek(0)
    b64 = base64.b64encode(output.read()).decode()
    filename = f"{results['newest_date_file_str']}æ—¥æŠ¥åˆ†æç»“è®º.xlsx"
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">ğŸ“¥ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š</a>'
    return href

# ==================== Streamlitä¸»ç•Œé¢ ====================
def main():
    st.markdown('<div class="main-header">ğŸ“Šç½‘ç›Ÿæ—¥æŠ¥åˆ†æ</div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‹ ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        **æ— éœ€å®‰è£…ä»»ä½•è½¯ä»¶ï¼Œç›´æ¥åœ¨ç½‘é¡µä¸­ä½¿ç”¨ï¼**
        
        ### ä½¿ç”¨æ­¥éª¤ï¼š
        1. ä¸Šä¼ Excelæ•°æ®æ–‡ä»¶
        2. ç³»ç»Ÿè‡ªåŠ¨åˆ†æOfferæ•°æ®  
        3. æŸ¥çœ‹åˆ†æç»“æœå¹¶ä¸‹è½½æŠ¥å‘Š
        
        ### æ”¯æŒåŠŸèƒ½ï¼š
        - âœ… è‡ªåŠ¨è¯†åˆ«æœ€æ–°ä¸¤å¤©æ—¥æœŸ
        - âœ… é«˜å·®å¼‚Offeræ™ºèƒ½åˆ†æ
        - âœ… Affiliateç»´åº¦ç²¾å‡†åˆ†æ
        - âœ… æ–°æ—§é¢„ç®—è‡ªåŠ¨åˆ¤æ–­
        - âœ… ä¸€é”®ä¸‹è½½å®Œæ•´æŠ¥å‘Š
        """)
        
        st.header("âš™ï¸ åˆ†æè§„åˆ™")
        st.info("""
        - é«˜å·®å¼‚ç­›é€‰ï¼šæµæ°´å·®ç»å¯¹å€¼â‰¥10ç¾é‡‘
        - Affiliateåˆ†æï¼šæ”¶å…¥å˜åŒ–â‰¥5ç¾é‡‘
        - é¢„ç®—åˆ¤æ–­ï¼šè¿‡å»6å¤©æ”¶å…¥>0=æ—§é¢„ç®—ï¼Œå¦åˆ™æ–°é¢„ç®—
        """)
        
        st.header("ğŸ“Š æ–‡ä»¶è¦æ±‚")
        st.success("""
        ç¡®ä¿ExcelåŒ…å«ä»¥ä¸‹å·¥ä½œè¡¨ï¼š
        - 1--all data
        - 3--åŒ¹é…å¹¿å‘Šä¸»  
        - 4--rejectäº‹ä»¶
        - 2-rejectè§„åˆ™
        """)
    
    # ä¸»å†…å®¹åŒº - æ–‡ä»¶ä¸Šä¼ 
    st.markdown("### ğŸ“¤ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ Excelæ–‡ä»¶")
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©Excelæ–‡ä»¶ï¼ˆæ”¯æŒ.xlsxæ ¼å¼ï¼‰",
        type=['xlsx'],
        help="è¯·ä¸Šä¼ åŒ…å«Offeræ•°æ®çš„å®Œæ•´Excelæ–‡ä»¶"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_details = {
            "æ–‡ä»¶å": uploaded_file.name,
            "æ–‡ä»¶ç±»å‹": uploaded_file.type,
            "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024:.2f} KB"
        }
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.json(file_details)
        
        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“– æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰", expanded=False):
            try:
                df_preview = pd.read_excel(uploaded_file, sheet_name='1--all data')
                st.dataframe(df_preview.head(), use_container_width=True)
                st.success(f"âœ… æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå…± {len(df_preview)} è¡Œè®°å½•")
            except Exception as e:
                st.error(f"âŒ æ•°æ®é¢„è§ˆå¤±è´¥ï¼š{str(e)}")
        
        # å¼€å§‹åˆ†ææŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹åˆ†ææ•°æ®", type="primary", use_container_width=True):
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # å¤„ç†æ•°æ®
            with st.spinner("æ•°æ®åˆ†æä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    results = process_daily_report_web(uploaded_file, progress_bar, status_text)
                    
                    # æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
                    st.markdown("### ğŸ“ˆ åˆ†æç»“æœæ‘˜è¦")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("é«˜å·®å¼‚Offeræ•°é‡", results['stats']['é«˜å·®å¼‚Offeræ•°é‡'])
                    with col2:
                        st.metric("æ—§é¢„ç®—Offer", results['stats']['æ—§é¢„ç®—Offeræ•°é‡'])
                    with col3:
                        st.metric("æ–°é¢„ç®—Offer", results['stats']['æ–°é¢„ç®—Offeræ•°é‡'])
                    
                    # ç»“æœæ˜¾ç¤ºæ ‡ç­¾é¡µ
                    tab1, tab2, tab3, tab4 = st.tabs([
                        "ğŸ“Š äºŒçº§å¹¿å‘Šä¸»æŠ¥è¡¨", 
                        "âœ… é«˜å·®å¼‚Offerè¯¦æƒ…", 
                        "ğŸ‘¥ äºŒçº§å¹¿å‘Šä¸»æŠ¥è¡¨", 
                        "ğŸ” AffiliateæŠ¥è¡¨"
                    ])
                    
                    with tab1:
                        st.dataframe(results['table1'], use_container_width=True)
                    
                    with tab2:
                        st.dataframe(results['table2'], use_container_width=True)
                    
                    with tab3:
                        st.dataframe(results['table3'], use_container_width=True)
                    
                    with tab4:
                        st.dataframe(results['table4'], use_container_width=True)
                    
                    # ä¸‹è½½åŠŸèƒ½
                    st.markdown("### ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š")
                    st.markdown(get_excel_download_link(results), unsafe_allow_html=True)
                    
                    st.success("ğŸ‰ åˆ†æå®Œæˆï¼ç‚¹å‡»ä¸Šæ–¹é“¾æ¥ä¸‹è½½å®Œæ•´æŠ¥å‘Š")
                    
                except Exception as e:
                    st.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
                    st.code(str(e))
    
    else:
        # æ¬¢è¿ç•Œé¢
        st.markdown("""
        <div class="upload-area">
            <h3>ğŸŒ æ¬¢è¿ä½¿ç”¨Offeræ•°æ®åˆ†æç³»ç»Ÿ</h3>
            <p>è¯·ä¸Šä¼ Excelæ–‡ä»¶å¼€å§‹åˆ†æï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å¤„ç†å¹¶ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š</p>
        </div>
        """, unsafe_allow_html=True)
        
        # åŠŸèƒ½è¯´æ˜
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### âœ¨ æ ¸å¿ƒåŠŸèƒ½
            - **æ™ºèƒ½æ—¥æœŸè¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ«æœ€æ–°ä¸¤å¤©æ•°æ®
            - **é«˜å·®å¼‚åˆ†æ**ï¼šç²¾å‡†ç­›é€‰é‡è¦å˜åŒ–Offer
            - **é¢„ç®—ç±»å‹åˆ¤æ–­**ï¼šè‡ªåŠ¨åŒºåˆ†æ–°æ—§é¢„ç®—
            - **Affiliateåˆ†æ**ï¼šè¯¦ç»†åˆ†ææ¯ä¸ªæµé‡æ–¹è´¡çŒ®
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ“‹ è¾“å‡ºå†…å®¹
            - è¡¨æ ¼ä¸€ï¼šæµæ°´æ€»ç»“
            - è¡¨æ ¼äºŒï¼šé«˜å·®å¼‚Offer IDè¯¦æƒ…  
            - è¡¨æ ¼ä¸‰ï¼šå¹¿å‘Šä¸»ç»¼åˆæŠ¥è¡¨
            - è¡¨æ ¼å››ï¼šæµé‡ç»¼åˆæŠ¥è¡¨
            - å®Œæ•´ExcelæŠ¥å‘Šä¸€é”®ä¸‹è½½
            """)

if __name__ == "__main__":
    main()
